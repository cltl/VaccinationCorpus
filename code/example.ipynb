{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read annotations from CoNLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder `annotations-pickle` contains all documents in the corpus with its annotations as pickled Python objects (created with the script `read_annotations.py`). This notebook illustrates how to load and use these objects in Python.\n",
    "\n",
    "Note: to be able to unpickle the files, you should make sure that your code can access the module `conll_data.py` (e.g. by putting it in the same directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single document\n",
    "The following illustrates how you can read one of the documents as a Document instance and print some information about its sentences, tokens and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = \"../data/annotations-pickle/21st-Century-Wire_20170627T181355.conll.pickle.gz\"\n",
    "with gzip.open(example_file, \"rb\") as infile:\n",
    "    doc = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics\n",
    "print(\"Number of sentences:\", len(doc.sentences))\n",
    "print(\"Number of tokens:\", len(doc.tokens))\n",
    "print(\"Number of unique words:\", len(set(doc.words)))\n",
    "print(\"Number of unique lemmas:\", len(set(doc.lemmas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific sentence\n",
    "sentence = doc.sentences[0]\n",
    "print(\"Text:\", sentence.text)\n",
    "print(\"Words:\", sentence.words)\n",
    "print(\"Lemmas:\", sentence.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific token\n",
    "token = sentence.get_token(token_id=\"13\") # or: sentence.tokens[12]\n",
    "print(\"Word:\", token.word)\n",
    "print(\"Lemma:\", token.lemma)\n",
    "print(\"POS:\", token.pos)\n",
    "print(\"Offset:\", token.offset_start, \"-\", token.offset_end)\n",
    "print(\"Full phrase:\", sentence.get_full_phrase(head_id=\"13\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics on the annotations\n",
    "print(f\"{len(doc.events)} events annotated\")\n",
    "print(f\"{len(doc.claims)} claims annotated\")\n",
    "print(f\"{len(doc.attr_cues)} attribution cues annotated\")\n",
    "print(f\"{len(doc.attr_contents)} attribution contents annotated\")\n",
    "print(f\"{len(doc.attr_sources)} attribution sources annotated\")\n",
    "print(f\"{len(doc.attr_relations)} attribution relations annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific event annotation\n",
    "doc.events[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect all multi-word events\n",
    "mw_events = [event for event in doc.events if len(event.tokens) > 1]\n",
    "for event in mw_events:\n",
    "    print(event.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific claim annotation\n",
    "print(doc.claims[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific attribution relation;\n",
    "# one AR can have multiple sources and cues\n",
    "ar = doc.attr_relations[-1]\n",
    "print(\"Content:\", ar.content.text)\n",
    "for source in ar.sources:\n",
    "    print(\"Source:\", source.text)\n",
    "for cue in ar.cues:\n",
    "    print(\"Cue:\", cue.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All documents\n",
    "\n",
    "The following illustrates how you can read one all documents as Document instances and get some overall information on all annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files = glob(\"../data/annotations-pickle/*.pickle.gz\")\n",
    "len(pickle_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all events\n",
    "events = []\n",
    "for pickle_file in tqdm(pickle_files):\n",
    "    with gzip.open(pickle_file, \"rb\") as infile:\n",
    "        doc = pickle.load(infile)\n",
    "        events.extend(doc.events)\n",
    "print(len(events), \"events annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent events\n",
    "event_texts = [event.tokens[0].lemma.lower() if len(event.tokens) == 1 else event.text.lower() for event in events]\n",
    "Counter(event_texts).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cues\n",
    "cues = []\n",
    "for pickle_file in tqdm(pickle_files):\n",
    "    with gzip.open(pickle_file, \"rb\") as infile:\n",
    "        doc = pickle.load(infile)\n",
    "        cues.extend(doc.attr_cues)\n",
    "print(len(cues), \"cues annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent cues\n",
    "cue_texts = [cue.tokens[0].lemma.lower() if len(cue.tokens) == 1 else cue.text.lower() for cue in cues]\n",
    "Counter(cue_texts).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
